{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62pAin4GN0Vh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wgkUKtHOb18"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCWJLowEN7eh"
      },
      "outputs": [],
      "source": [
        "cd gdrive/MyDrive/projects-bias-bot/src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq8ReWZyNNoS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "\n",
        "from tqdm import tqdm\n",
        "import gensim.downloader as api\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from Article import Article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tWZS2ioNRkb"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "\t\"\"\"Long Short-Term Memory deep learning model\"\"\"\n",
        "\tdef __init__(self, input_size, emb_dim, output_size, num_layers, embeds=None):\n",
        "\t\t\"\"\"initialize model\"\"\"\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.emb = nn.Embedding(input_size, emb_dim)\n",
        "\t\tif embeds is not None:\n",
        "\t\t\tself.emb.weight = nn.Parameter(torch.Tensor(embeds))\n",
        "\t\t\n",
        "\t\tself.lstm = nn.LSTM(emb_dim, emb_dim, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
        "\t\tself.linear = nn.Linear(emb_dim*2, output_size)\n",
        "\t\t\n",
        "\tdef forward(self, input_seq):\n",
        "\t\t\"\"\"forward direction of neural network\"\"\"\n",
        "\n",
        "\t\tembeds = self.emb( input_seq )\n",
        "\n",
        "\t\toutput_seq , (h_last, c_last) = self.lstm( embeds )\n",
        "\n",
        "\t\th_direc_1 = h_last[4,:,:]\n",
        "\t\th_direc_2 = h_last[5,:,:]\n",
        "\t\th_direc_12 = torch.cat( (h_direc_1, h_direc_2), dim=1 )\n",
        "\n",
        "\t\treturn self.linear(h_direc_12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMY4RBSdNUGR"
      },
      "outputs": [],
      "source": [
        "def load_vocab(data, include_text=True):\n",
        "\t\"\"\"return a dictionary of each word in the corpus and its frequency\"\"\"\n",
        "\tvocab = dict()\n",
        "\tfor item in data:\n",
        "\t\ttext = item.headline\n",
        "\t\tif include_text:\n",
        "\t\t\ttext += item.text\n",
        "\t\tfor word in text:\n",
        "\t\t\tif word in vocab:\n",
        "\t\t\t\tvocab[word] += 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tvocab[word] = 1\n",
        "\tvocab = dict(sorted(vocab.items(), key=lambda item: -item[1]))\n",
        "\treturn vocab\n",
        "\n",
        "def make_vocab_dict(vocab):\n",
        "\t\"\"\"return a dictionary that maps each word in the corpus to a token\"\"\"\n",
        "\tword_to_index = {\"UNK\":0,\"FOX\":1,\"CNN\":2,\"BBC\":3,\"Liberal\":4,\"Conservative\":5,\"Independent\":6,\"Other\":7}\n",
        "\tcount = len(word_to_index)+1\n",
        "\tfor word in vocab:\n",
        "\t\tif word not in word_to_index:\n",
        "\t\t\tword_to_index[word] = count \n",
        "\t\t\tcount += 1\n",
        "\treturn word_to_index\n",
        "\n",
        "def load_bigrams(data):\n",
        "\t\"\"\"return a dictionary of each bigram in the corpus and its frequency\"\"\"\n",
        "\tbigram_to_index = dict()\n",
        "\tcount = 0\n",
        "\tfor article in data:\n",
        "\t\tfull_text = article.headline + article.text\n",
        "\t\tfor i, word in enumerate(full_text):\n",
        "\t\t\tif i==0:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tbigram = (full_text[i-1],word)\n",
        "\t\t\tif bigram not in bigram_to_index:\n",
        "\t\t\t\tbigram_to_index[bigram]=count\n",
        "\t\t\t\tcount+=1\n",
        "\treturn bigram_to_index\n",
        "\n",
        "def make_unigrams(data, word_to_index, party=None, include_text=True):\n",
        "\t\"\"\"return tokenized input features, using unigrams\"\"\"\n",
        "\tprocessed_data = []\n",
        "\tfor article in data:\n",
        "\t\tdatapoint = []\n",
        "\t\tif party==None and article.party not in [\"Liberal\", \"Conservative\"]:\n",
        "\t\t\tcontinue\n",
        "\t\telif article.party != party and party!=\"Combined\":\n",
        "\t\t\tcontinue\n",
        "\t\telif party==\"Combined\":\n",
        "\t\t\tdatapoint = [word_to_index[article.party]]\n",
        "\t\tdatapoint += [word_to_index[article.source]] + [word_to_index[word] if word in word_to_index else word_to_index[\"UNK\"] for word in article.headline]\n",
        "\t\tif include_text:\n",
        "\t\t\tdatapoint += [word_to_index[word] if word in word_to_index else word_to_index[\"UNK\"] for word in article.text]\n",
        "\t\tlabel = label_to_index[article.label]\n",
        "\n",
        "\t\tprocessed_data.append( (datapoint, label) )\n",
        "\treturn processed_data\n",
        "\n",
        "def make_bigrams(data, bigram_to_index, party):\n",
        "\t\"\"\"return tokenized input features, using bigrams\"\"\"\n",
        "\tprocessed_data = []\n",
        "\tfor article in data:\n",
        "\t\tif article.party != party:\n",
        "\t\t\tcontinue\n",
        "\t\tdatapoint = []\n",
        "\t\tfull_text = article.headline + article.text\n",
        "\t\tfor i, word in enumerate(full_text):\n",
        "\t\t\tif i==0:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdatapoint.append(bigram_to_index[(full_text[i-1],word)])\n",
        "\t\tlabel = label_to_index[article.label]\n",
        "\n",
        "\t\tprocessed_data.append( (datapoint, label) )\n",
        "\treturn processed_data\n",
        "\t\n",
        "def split_data(processed_data):\n",
        "\treturn processed_data[:math.floor(0.9*len(processed_data))], processed_data[math.floor(0.9*len(processed_data)):]\n",
        "\n",
        "\n",
        "def process_batch(batch):\n",
        "\t\"\"\"convert batch to tensors\"\"\"\n",
        "\tx = torch.zeros((len(batch), max_len), dtype=torch.long)\n",
        "\ty = torch.zeros((len(batch)), dtype=torch.long)\n",
        "\tfor idx, (text, label) in enumerate(batch):\n",
        "\t\tx[idx,:len(text)] = torch.Tensor(text)\n",
        "\t\ty[idx] = label\n",
        "\treturn x.to(device), y.to(device)\n",
        "\n",
        "def get_error(scores, labels):\n",
        "\t\"\"\"get error on a batch of scores based on their expected labels\"\"\"\n",
        "\tbs=scores.size(0)\n",
        "\tpredicted_labels = scores.argmax(dim=1)\n",
        "\tindicator = (predicted_labels == labels)\n",
        "\tnum_matches=indicator.sum()\n",
        "\t\n",
        "\treturn 1-num_matches.float()/bs  \n",
        "\n",
        "def evaluate(model, test_data):\n",
        "\t\"\"\"evaluate the model on test data\"\"\"\n",
        "\twith torch.no_grad():\n",
        "\t\tmodel.eval()\n",
        "\t\tx_test, y_test = process_batch(test_data)\n",
        "\t\n",
        "\t\tpred_y_test = model(x_test)\n",
        "\t\n",
        "\t\tlabels = y_test.tolist()\n",
        "\t\tpredictions = [torch.argmax(pred).item() for pred in pred_y_test]\n",
        "\n",
        "\t\tprint(classification_report(labels, predictions, target_names=[\"Is Biased\",\"Is Not Biased\"], zero_division=0))\n",
        "\t\tprint(\"Error:\",get_error(pred_y_test, y_test).item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlUM4cNbNZ1M"
      },
      "outputs": [],
      "source": [
        "device= torch.device(\"cuda\")\n",
        "print(device)\n",
        "\n",
        "# Run only for a single political group\n",
        "# party = \"Liberal\"\n",
        "# party = \"Conservative\"\n",
        "party = \"Combined\"\n",
        "\n",
        "mode = \"unigram\"\n",
        "\n",
        "# Load data\n",
        "print(\"Loading data...\")\n",
        "with open(\"../data/processed_articles.p\", \"rb\") as f:\n",
        "\tdata = pickle.load(f)\n",
        "\trandom.shuffle(data)\n",
        "\n",
        "vocab = load_vocab(data)\n",
        "print(vocab)\n",
        "\n",
        "vocab_cutoff=9000\n",
        "trimmed_vocab=dict()\n",
        "for i, (word, count) in enumerate(vocab.items()):\n",
        "\tif i <= vocab_cutoff:\n",
        "\t\ttrimmed_vocab[word] = count\n",
        "\n",
        "word_to_index = make_vocab_dict(trimmed_vocab)\n",
        "index_to_word = {v: k for k, v in word_to_index.items()}\n",
        "\n",
        "print(word_to_index)\n",
        "print(index_to_word)\n",
        "\n",
        "bigram_to_index = load_bigrams(data)\n",
        "index_to_bigram = {v: k for k, v in bigram_to_index.items()}\n",
        "\n",
        "\n",
        "label_to_index = {\"is-biased\":0, \"is-not-biased\":1}\n",
        "max_len = max([len(article.headline + article.text) for article in data]) + 3\n",
        "\n",
        "print(\"Creating train data set...\")\n",
        "\n",
        "if mode==\"unigram\":\n",
        "\tunigrams = make_unigrams(data, word_to_index, party)\n",
        "\ttrain_data, test_data = split_data(unigrams)\n",
        "\tinput_size = len(word_to_index)+1\n",
        "elif mode==\"bigram\":\n",
        "\tbigrams = make_bigrams(data, bigram_to_index, party)\n",
        "\ttrain_data, test_data = split_data(bigrams)\n",
        "\tinput_size = len(bigram_to_index)+1\n",
        "\n",
        "# Hyper parameters\n",
        "output_size = 2 \n",
        "num_layers = 3\n",
        "batch_size = 16\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "\n",
        "#Load pre-trained word embeddings, if using them.\n",
        "# embeds = api.load('glove-twitter-25').vectors\n",
        "# emb_dim = embeds.shape[1]\n",
        "\n",
        "embeds = None\n",
        "emb_dim = 50\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=False, collate_fn=process_batch)\n",
        "\n",
        "num_biased = len([item for item in train_data if item[1]==0])\n",
        "num_unbiased = len([item for item in train_data if item[1]==1])\n",
        "\n",
        "print(\"num biased: \", num_biased)\n",
        "print(\"num unbiased: \", num_unbiased)\n",
        "\n",
        "weights = torch.tensor([num_biased/num_biased,num_biased/num_unbiased]).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "# Build model\n",
        "model = LSTM(input_size, emb_dim, output_size, num_layers, embeds).to(device)\n",
        "# criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tQz7lecFZZs"
      },
      "outputs": [],
      "source": [
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkmUxnswOsUZ"
      },
      "outputs": [],
      "source": [
        "print(len(word_to_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEHLWXqQOvSG"
      },
      "outputs": [],
      "source": [
        "print(len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2JEnK80npDG"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  item1 = train_data[i]\n",
        "  print([index_to_word[index] for index in item1[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WJq8cCCNWg7"
      },
      "outputs": [],
      "source": [
        "# Train loop\n",
        "for epoch in range(epochs):\n",
        "\n",
        "\tprint(f\"\\n\\nEpoch {epoch}\")\n",
        "\n",
        "\tif epoch >= 5:\n",
        "\t\tlearning_rate = learning_rate/2\n",
        "\toptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\tmodel.train()\n",
        "\n",
        "\trunning_error = 0\n",
        "\tcount = 0\n",
        "\n",
        "\tfor x,y in tqdm(train_dataloader):\n",
        "   \n",
        "\t\tif x.size()[0] != batch_size:\n",
        "\t\t\tcontinue \n",
        "\n",
        "\t\tscores = model(x)\n",
        "\t\tscores = scores.view(-1,2)\n",
        "\n",
        "\t\tloss = criterion(scores, y)\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\terror = get_error(scores, y)\n",
        "\t\trunning_error += error.item()\n",
        "\t\tcount += 1\n",
        "\n",
        "\n",
        "\tprint(\"\\nEvaluate on test:\")\n",
        "\tevaluate(model, test_data)\n",
        "\tprint(\"\\nRunning Error:\", running_error/count)\n",
        "\n",
        "# Evaluate\n",
        "torch.save(model.state_dict(),f\"model_{party}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05tAP04VD3AB"
      },
      "outputs": [],
      "source": [
        "evaluate(model, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgQ1hEWERXLQ"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}